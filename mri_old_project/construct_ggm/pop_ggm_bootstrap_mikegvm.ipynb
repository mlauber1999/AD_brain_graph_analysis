{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import os\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.covariance import GraphicalLassoCV,GraphicalLasso\n",
    "from networkx.generators.community import gaussian_random_partition_graph\n",
    "from sklearn.model_selection import ValidationCurveDisplay\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind\n",
    "import nibabel as nib \n",
    "# import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import glob as glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup \n",
    "Seed the random number generator once, so the entire notebook is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all ADNI and NACC patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_gmv = pd.read_csv(\"/data2/MRI_PET_DATA/graph/csvs/graph_gmv_volumes/parcellation_volumes_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in adni prog and adni stab for bootstrapping (these ones have already been normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_gmv_prog_lr = pd.read_csv(\"/data2/MRI_PET_DATA/graph/csvs/graph_gmv_volumes/mike_gmv_adni_prog_norm.csv\")\n",
    "adni_gmv_stab_lr = pd.read_csv('/data2/MRI_PET_DATA/graph/csvs/graph_gmv_volumes/mike_gmv_adni_stab_norm.csv')\n",
    "\n",
    "adni_gmv_stab_lr.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some regions have zero volume, let's drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adni_gmv_prog_lr == 0).sum().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_gmv_prog_lr = adni_gmv_prog_lr.drop(['vol_lInfLatVen','vol_rInfLatVen','vol_lOC','vol_rOC'], axis=1)\n",
    "adni_gmv_stab_lr = adni_gmv_stab_lr.drop(['vol_lInfLatVen','vol_rInfLatVen','vol_lOC','vol_rOC'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this there are no more regions with zero volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_present = (adni_gmv_stab_lr == 0).any().any()\n",
    "print(zero_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now let's drop `RID`, `TIV`, and `Dataset`, we don't need that information to compute the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_gmv_prog_lr = adni_gmv_prog_lr.drop(['RID','TIV','Dataset'], axis=1)\n",
    "adni_gmv_stab_lr = adni_gmv_stab_lr.drop(['RID','TIV','Dataset'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine left and right regions\n",
    "The number of samples is only slightly larger than the number of features. Let's combine the measured values in corresponding left/right regions of the brain, which cuts the number of features in half and is biologically reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_gmv_prog_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that combines the left and right volumes for an region \n",
    "\n",
    "def combine_regions(input_df):\n",
    "    # Assuming the region names can be extracted from the column names\n",
    "    regions = set(col.split('_')[1][1:] for col in input_df.columns if col.startswith('vol_'))\n",
    "\n",
    "    # Dictionary to hold the sum of the left and right volumes for each region\n",
    "    comb_regions = {}\n",
    "\n",
    "    # Iterate through each region, summing the left and right volumes\n",
    "    for region in regions:\n",
    "        left_col = f'vol_l{region}'\n",
    "        right_col = f'vol_r{region}'\n",
    "        sum_col = f'vol_{region}'\n",
    "        comb_regions[sum_col] = input_df[left_col] + input_df[right_col]\n",
    "\n",
    "    # Create a new DataFrame using the dictionary\n",
    "    combined_df = pd.DataFrame(comb_regions)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Usage:\n",
    "\n",
    "\n",
    "adni_gmv_prog = combine_regions(adni_gmv_prog_lr)\n",
    "adni_gmv_stab = combine_regions(adni_gmv_stab_lr)\n",
    "\n",
    "adni_gmv_prog.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data\n",
    "Center the data and scale them to have unit standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_norm = StandardScaler().set_output(transform='pandas').fit_transform(adni_gmv_prog)\n",
    "stable_norm = StandardScaler().set_output(transform='pandas').fit_transform(adni_gmv_stab)\n",
    "\n",
    "progs_norm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the output of standard scaler is a numpy array so need to reconvert it \n",
    "# progs_norm = pd.DataFrame(progs_norm, columns=adni_gmv_prog.columns)\n",
    "# stable_norm = pd.DataFrame(stable_norm,columns=adni_gmv_stab.columns)\n",
    "# print(progs_norm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double checking there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs_norm.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bootstrap samples\n",
    "We use bootstrapping (with replacement) before the graphical lasso cv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 100\n",
    "\n",
    "bootstrap_precision_matrices = []\n",
    "bootstrap_samples = []\n",
    "\n",
    "for _ in tqdm(range(num_bootstrap_samples)):\n",
    "    \n",
    "    #sample with replacement\n",
    "    bootstrap_sample = progs_norm.sample(n=len(progs_norm),replace=True).sort_index().reset_index(drop=True)\n",
    "    \n",
    "    bootstrap_samples.append(bootstrap_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for infinite and null values, the should both be false:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.any(np.isinf(bootstrap_samples)))\n",
    "print(bootstrap_sample.isna().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check datatypes \n",
    "\n",
    "if I give it alphas [1,10] it looks like it drops almost all of the connections \n",
    "   \n",
    "How I can be evaluating how well my model is fitting the data?\n",
    "\n",
    "2 matrices estimates (from graphical lasso and then the actual empirical) to do difference you could \n",
    "\n",
    "if I just want estimate of how well its performing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- should we reset index?\n",
    "- use the sklearn sampler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV to select $L_1$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphicalLasso(alpha=0.1, max_iter=100, tol=1e-2, mode='cd',assume_centered=True,covariance=None) #if I predefine an alpha it will take less time \n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model is very sensitive to the choice of $\\alpha$, let's see what the sparsity looks like as a function of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.geomspace(0.1,0.9,64)\n",
    "precision_sparsities = []\n",
    "covariance_sparsities = []\n",
    "\n",
    "for alpha in alphas: \n",
    "    \n",
    "    model = GraphicalLasso(alpha=alpha, max_iter=200, tol=1e-2, mode='cd', assume_centered=True)\n",
    "    model.fit(progs_norm)\n",
    "\n",
    "    precision_sparsities.append(np.count_nonzero(model.precision_)/(model.precision_.size))\n",
    "    covariance_sparsities.append(np.count_nonzero(model.covariance_)/(model.covariance_.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing $\\alpha$ < 0.2 has no effect on the sparsity of the covariance matrix (there might still be some shrinkage though). We should choose the optimal value of $\\alpha$ by looking at the cross validated performance of the estimator, and thinking about how much sparsity we want in the final graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas,precision_sparsities,label=\"Precision Matrix\")\n",
    "plt.plot(alphas,covariance_sparsities,label=\"Covariance Matrix\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Fraction of nonzero entries\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationCurveDisplay.from_estimator(estimator=model,\n",
    "                                      X=progs_norm,\n",
    "                                      y=None,\n",
    "                                      cv=10,\n",
    "                                      param_name='alpha',\n",
    "                                      param_range=np.linspace(0.1,0.9,16),\n",
    "                                      n_jobs=-1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, with increasing $\\alpha$ our sparse approximation of the covariance matrix gets worse. \n",
    "\n",
    "- There's an inflection point around $\\alpha = 0.5$, does it mean anything?\n",
    "- At $\\alpha=0.5$ the covariance matrix is still 90% filled, it might be a good idea to make it much more and then decrease alpha gradually if we cannot see any difference between the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train graphical model on bootstrapped sample \n",
    "find score on each num bootstrap sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for bootstrap_sample in tqdm(bootstrap_samples):\n",
    "    model = GraphicalLasso(alpha=0.7,max_iter=150, tol=1e-3) #if I predefine an alpha it will take less time \n",
    "    \n",
    "    model.fit(bootstrap_sample)\n",
    "    models.append(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different metrics to calc \n",
    "#gpe, clus_coeff \n",
    "#density nx.density(G)\n",
    "#eigenvector centrality nx.eigenvector_centrality(G) seems like its not a single value \n",
    "#assostivity coeff nx.degree_assortativity_coefficient(G) \n",
    "#diameter nx.diameter(G) -  Gives the diameter of the largest connected component in the graph, representing the longest shortest path between any pair of nodes. gave error \n",
    "#radius nx.radius - computes the radius of the largest connected compmenet gave error \n",
    "#number connected components nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphical lasso cv not converging \n",
    "#can adjust the tolerance, regularization parameter alphas, change solver method, increase max iterations, or random seed \n",
    "#example \n",
    "#model = GraphicalLassoCV(tol=1e-3)  # Increase tolerance level\n",
    "#alphas = [0.1, 1.0, 10.0]  # Example list of alpha values to search\n",
    "#model = GraphicalLassoCV(alphas=alphas)\n",
    "\n",
    "#model = GraphicalLassoCV(solver='graph_lasso')  # Try a different solver\n",
    "#model = GraphicalLassoCV(max_iter=500)  # Increase maximum iterations\n",
    "#model = GraphicalLassoCV(random_state=42)  # Set a random seed\n",
    "#graphical lasso -  WITHOUT BOOTSTRAP  \n",
    "#converges with 500 iterations \n",
    "#estimates the precision matrix of the data (inverse cov mat which models the partial correlations between vars)\n",
    "#uses lasso penalty, during training the model iteratively updates the estimated precision matrix using current hyperparamter values until it converges to a set of values that minimize the loss function \n",
    "# model = GraphicalLassoCV(cv=5,max_iter=500) #cv=5 specifies 5-fold cross validation strategy to optimize model hyperparameters \n",
    "# model.fit(progs_norm)\n",
    "#have 1 rv per node (volumes), find out the optimization details, theorteically estimating corr mat of vars \n",
    "\n",
    "\n",
    "#have data, then unconnected random var,s est cov mat, and this estimation has penalty to force very small numbers to be 0 (force some sparsity) then interpret the inverse cov matrix as an adjacency matrix, and then visualize as a graph \n",
    "#makes sense to trat as random var, they are connecte din some sense if they are correlated \n",
    "\n",
    "#drop the very small nunvbwers, l1 sets very small things to 0, choses hyper parater by cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RuntimeWarning: invalid value encountered in subtract x = asanyarray(arr - arrmean) \n",
    "#check data for nan values \n",
    "nan_mask = progs_norm.isna()\n",
    "nan_count = nan_mask.sum().sum()\n",
    "print(nan_count)\n",
    "\n",
    "#under the assumption the vars are gaussian and correlated oit is estimated cov matrix \n",
    "#plot histrogram (for one brain region)\n",
    "#if you have random var that is sum of other random var, with finite variance, then CLT holds, if its the sum of many processed, then it's reasonably gaussian \n",
    "\n",
    "\n",
    "#for embeddings - sklearkn might have covariance betwen 2 random vars, use dot product of vectors instead of product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for graph visualization, doesn't work for bootstrapped because there's more than one pop graph \n",
    "#node size based on connectivity visualization \n",
    "#assigns node labels based on the column id \n",
    "#this doesn't work because it's the bootstrap sample list \n",
    "# precision_matrix_p = model.precision_\n",
    "# np.fill_diagonal(precision_matrix_p, 0) #removes self connections by replacing the diagnonal of matrix with 0 \n",
    "\n",
    "# G_prog = nx.Graph(precision_matrix_p)\n",
    "# #create a dictionary that maps old node labels to new node labels\n",
    "# node_labels = {i: label for i, label in enumerate(progs_norm.columns)}\n",
    "\n",
    "# #relabel the nodes in the graph using the dictionary\n",
    "# G_prog = nx.relabel_nodes(G_prog, node_labels)\n",
    "\n",
    "# # Assuming you already have precision_matrix_np and G_n_prog as in your code\n",
    "# # Calculate the node degrees (connectivity strength)\n",
    "# node_degrees = dict(G_prog.degree())\n",
    "\n",
    "# # Scale the node sizes based on node degrees\n",
    "# node_sizes = [20 * node_degrees[node] for node in G_prog.nodes()]\n",
    "\n",
    "# # Create a colormap for node colors based on node degrees\n",
    "# node_colors = list(node_degrees.values())\n",
    "\n",
    "# # Draw the graph with node sizes and colors\n",
    "# pos = nx.random_layout(G_prog)\n",
    "# nx.draw(\n",
    "#     G_prog,\n",
    "#     pos,\n",
    "#     with_labels=True,\n",
    "#     font_size=7,\n",
    "#     style=\"dotted\",\n",
    "#     node_color=node_colors,\n",
    "#     cmap=plt.cm.Reds,\n",
    "#     node_size=node_sizes,\n",
    "#     alpha=0.8,\n",
    "#     width=0.3,\n",
    "# )\n",
    "\n",
    "# plt.title(\"Progressive MCI Population Graphical Model NACC\", fontsize=22)\n",
    "# plt.show()\n",
    "\n",
    "#the random layout changes, to have the same one run the layout finctiopn first, choose what I want and then try it later \n",
    "#circular one might be good or spectral (bc it uses info on the degree of each node aware of hubs)\n",
    "#since these are random seed rnadom generator to generate same layout \n",
    "#generate positions once and then pass same poisition dictioary \n",
    "#network x is generating citionary of 2d positins to draw function \n",
    "#draw in circle (then spot patterns that way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc metrics \n",
    "# terating through each bootsrap sample model, calculating the graph metrics, and then storing the metrics for eahc model in a dataframe \n",
    "metrics_data = []\n",
    "#to get variance, \n",
    "\n",
    "#keep track of index with enumerate \n",
    "for model_num, model in enumerate(models,start=1):\n",
    "    precision_matrix_p = model.precision_\n",
    "    np.fill_diagonal(precision_matrix_p, 0) #removes self connections by replacing the diagnonal of matrix with 0 \n",
    "    G_prog = nx.Graph(precision_matrix_p)\n",
    "    node_labels = {i: label for i, label in enumerate(progs_norm.columns)}\n",
    "    #relabel the nodes in the graph using the dictionary\n",
    "    G_prog = nx.relabel_nodes(G_prog, node_labels)\n",
    "    #now calculate the metrics and store them \n",
    "    gpe = nx.global_efficiency(G_prog) \n",
    "    clustering_coefficient = nx.average_clustering(G_prog)\n",
    "    density = nx.density(G_prog)\n",
    "    # eigen_cen = nx.eigenvector_centrality(G_prog)\n",
    "    ass_coeff = nx.degree_assortativity_coefficient(G_prog)\n",
    "    # diameter = nx.diameter(G_prog)\n",
    "    # radius = nx.radius(G_prog)\n",
    "\n",
    "\n",
    "    #create dictionary for current models data \n",
    "    metrics_dic = {\n",
    "        'model_num': model_num,\n",
    "        'gpe': gpe,\n",
    "        'clus_coeff':clustering_coefficient,\n",
    "        'density': density,\n",
    "        'ass_coeff': ass_coeff\n",
    "    }\n",
    "    metrics_data.append(metrics_dic)\n",
    "\n",
    "\n",
    "#turn the list of dictionaries with each model info into a df\n",
    "metrics_data = pd.DataFrame(metrics_data)\n",
    "metrics_data.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/full_bootstrap_models_prog_metrics.csv')\n",
    "# print(metrics_data.dtypes)\n",
    "print(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metrics_data)\n",
    "#calc variance for each metric (which is col for each) like for mean \n",
    "#plot the variance for each metric/col across diff num samples (training curve)\n",
    "# sklearn has training curve display \n",
    "# do it on estimator (graph lasso cv and training set) but do it on pop_ggm_code without bootstrap (good to have on poster)\n",
    "# on bootstrapped data SSE ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap of precision matrix (precision matrix is the inverse of the covariance matrix)\n",
    "\n",
    "# Assuming models is your list of models\n",
    "model_num = 0  # Change this to get the precision matrix of other models\n",
    "precision_matrix = models[model_num].precision_\n",
    "\n",
    "# Set the diagonal to zero if desired\n",
    "np.fill_diagonal(precision_matrix, 0)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(precision_matrix, cmap='coolwarm', annot=False, vmin=-1, vmax=.25)  # assuming values range from -1 to 1\n",
    "plt.title(f'Precision Matrix of Model {model_num + 1}')\n",
    "plt.show()\n",
    "print(np.min(precision_matrix), np.max(precision_matrix))\n",
    "\n",
    "#stronger parital correlation is red but what if \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run bootstrap for stable df \n",
    "# np.random.seed(3)\n",
    "stab_num_bootstrap_samples = 50\n",
    "stab_bootstrap_precision_matrices = []\n",
    "stab_bootstrap_samples = []\n",
    "for x in range(stab_num_bootstrap_samples):\n",
    "    #sample with replacement, randomstate =1 for reporoducibility \n",
    "    stab_bootstrap_sample = stable_norm.sample(n=len(stable_norm),replace=True)\n",
    "    #append resamples df to a list \n",
    "    stab_bootstrap_samples.append(stab_bootstrap_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bootstrap and plot stable \n",
    "# #bootstrap for stable adni \n",
    "# stab_num_bootstrap_samples = 5 \n",
    "# stab_bootstrap_precision_matrices = []\n",
    "# stab_bootstrap_samples = []\n",
    "# for x in range(stab_num_bootstrap_samples):\n",
    "#     #sample with replacement, randomstate =1 for reporoducibility \n",
    "#     stab_bootstrap_sample = stable_norm.sample(n=len(stable_norm),replace=True, random_state=1)\n",
    "#     #append resamples df to a list \n",
    "#     stab_bootstrap_samples.append(stab_bootstrap_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run graphical model on bootstrapped sample \n",
    "stab_models = []\n",
    "for stab_bootstrap_sample in tqdm(stab_bootstrap_samples):\n",
    "    #if I give it alphas [1,10] it looks like it drops almost all of the connections \n",
    "    \n",
    "    stab_model = GraphicalLassoCV(cv=5,max_iter=50,tol=1e-3)\n",
    "    stab_model.fit(stab_bootstrap_sample)\n",
    "    stab_models.append(stab_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stab_models.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/full_bootstrap_models_stab.csv')\n",
    "#this doesn't work because the bootstrap is a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the bootstrap values are unique \n",
    "stab_bootstrap_samples[1].index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot graph just for viualization doesn't work if there are more than one \n",
    "# #this doesn't work because the fraph is \n",
    "# precision_matrix_s = stab_model.precision_\n",
    "# np.fill_diagonal(precision_matrix_s, 0) #removes self connections by replacing the diagnonal of matrix with 0 \n",
    "\n",
    "# G_stab = nx.Graph(precision_matrix_s)\n",
    "# #create a dictionary that maps old node labels to new node labels\n",
    "# node_labels = {i: label for i, label in enumerate(stable_norm.columns)}\n",
    "\n",
    "# #relabel the nodes in the graph using the dictionary\n",
    "# G_stab = nx.relabel_nodes(G_stab, node_labels)\n",
    "\n",
    "# #visualize the relabeled graph\n",
    "# pos = nx.random_layout(G_stab)\n",
    "# nx.draw(G_stab, pos, with_labels=True, font_size=7, style=\"dotted\",\n",
    "#         node_color=range(len(G_stab)), cmap=plt.cm.Blues,\n",
    "#         node_size=150*len(G_stab)/154, alpha=.8, width=.3)\n",
    "# plt.title(\"Stable MCI Population Graphical Model ADNI\", fontsize=22)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming stable_norm and stab_models are already defined somewhere\n",
    "\n",
    "stab_metrics_data = []\n",
    "\n",
    "for stab_model_num, stab_model in enumerate(stab_models):\n",
    "    precision_matrix_stab = stab_model.precision_\n",
    "    np.fill_diagonal(precision_matrix_stab, 0)  # removes self connections by replacing the diagonal of matrix with 0\n",
    "    G_stab = nx.Graph(precision_matrix_stab)\n",
    "    # create a dictionary that maps old node labels to new node labels\n",
    "    stab_node_labels = {i: label for i, label in enumerate(stable_norm.columns)}\n",
    "    # relabel the nodes in the graph using the dictionary\n",
    "    G_stab = nx.relabel_nodes(G_stab, stab_node_labels)\n",
    "    # now calculate the metrics and store them\n",
    "    stab_gpe = nx.global_efficiency(G_stab)\n",
    "    stab_clustering_coefficient = nx.average_clustering(G_stab)\n",
    "\n",
    "    # Assuming you want to store metrics for stab (stability) models,\n",
    "    # not prog (progression) models as shown in the second snippet\n",
    "    stab_density = nx.density(G_stab)\n",
    "    stab_ass_coeff = nx.degree_assortativity_coefficient(G_stab)\n",
    "\n",
    "    # metrics dictionary\n",
    "    stab_metrics_dic = {'model_num': stab_model_num,\n",
    "                        'gpe': stab_gpe,\n",
    "                        'clus_coeff': stab_clustering_coefficient,\n",
    "                        'density': stab_density,\n",
    "                        'ass_coeff': stab_ass_coeff\n",
    "                        }\n",
    "\n",
    "    stab_metrics_data.append(stab_metrics_dic)\n",
    "\n",
    "stab_metrics_data = pd.DataFrame(stab_metrics_data)\n",
    "stab_metrics_data.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/50_bootstrap_models_stab_metrics.csv')\n",
    "print(stab_metrics_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of calcing mean just calc from data instead \n",
    "#add col where the p val is greater than .05\n",
    "\n",
    "# Initialize lists or a DataFrame to store your results\n",
    "cols = []\n",
    "p_values = []\n",
    "t_stats = []\n",
    "\n",
    "for col in metrics_data.columns:  \n",
    "    if col != 'model_num':\n",
    "    # Get data for this brain region from both datasets\n",
    "        progs_data = metrics_data[col]\n",
    "        stab_data = stab_metrics_data[col]\n",
    "        \n",
    "        # Perform t-test\n",
    "        t_stat, p_val = stats.ttest_ind(progs_data, stab_data, equal_var=False)  # Assuming variance might not be equal\n",
    "        \n",
    "        # Store results\n",
    "        cols.append(col)\n",
    "        t_stats.append(t_stat)\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # Combine results into a DataFrame for easy viewing and further analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'Brain Region': cols,\n",
    "        'T-Statistic': t_stats,\n",
    "        'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Adding the Significant column based on the P-Value\n",
    "results_df['Significant'] = results_df['P-Value'] < 0.05\n",
    "\n",
    "# Display or save the results\n",
    "print(results_df)\n",
    "# Optionally save to a CSV file\n",
    "# results_df.to_csv('t_test_results.csv', index=False)\n",
    "\n",
    "#the resulting negative t stats mean the progs have lower volume than the stab which is good \n",
    "results_df.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/50_bootstrap_models_ttest.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting t test results:\n",
    "1. GPE was lower for progressive MCI\n",
    "-Global path effiency is a measure of the effiency of information exchange across the network, a lower efficency indicates that the graph network is not effiently structured and that information has to travel more indirectly between nodes \n",
    "\n",
    "2. clustering coefficent was lower for progressive MCI\n",
    "- Clustering coefficient is extent to which nodes in a graph are organized into clusters. \n",
    "- Specifically, the average clustering coefficient calculates the mean of local clustering coefficients of all the vertices in the network. A higher clustering coefficient indicates a higher degree of clustering in the network.\n",
    "\n",
    "3. Graph density was lower for progressive MCI \n",
    "- density is a measure of how closely knit the network is (low density value is a more sparse network)\n",
    "\n",
    "4. Assortivity coefficient was lower for progressive MCI \n",
    "- correlation coefficient for degrees of connected nodes \n",
    "- lower assortativity is indicates that nodes with a high degree tend to connect with nodes of low degree (dissasortive mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now try for nacc \n",
    "# comb_gmv_nacc = pd.read_csv(\"/data2/MRI_PET_DATA/graph/csvs/graph_gmv_volumes/mike_gmv_nacc_combo.csv\")\n",
    "# comb_gmv_nacc = comb_gmv_nacc.drop(['Unnamed: 0'], axis=1)\n",
    "# print(comb_gmv_nacc.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_prog_rids = pd.read_csv(\"/data2/MRI_PET_DATA/graph/NACC/Morph/mri_atlas/morph/roi/NACC_progressors_vol.csv\")\n",
    "nacc_stab_rids = pd.read_csv(\"/data2/MRI_PET_DATA/graph/NACC/Morph/mri_atlas/morph/roi/NACC_stable_vol.csv\")\n",
    "# print(nacc_prog_rids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_prog_rids = nacc_prog_rids.drop(['Unnamed: 0'], axis=1) #drop col \n",
    "nacc_stab_rids = nacc_stab_rids.drop(['Unnamed: 0'],axis=1)\n",
    "# print(nacc_stab_rids.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nacc_stab_rids.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratify them into prog and stable for nacc \n",
    "#double check these are correct \n",
    "\n",
    "#do this by cross referencing the stable dfs that I have before from other csv files \n",
    "#these are all object datatype so hopefull it will work without converting them to int \n",
    "\n",
    "# nacc_prog_rids['RID'] = nacc_prog_rids[\"RID\"].astype('int64')\n",
    "# nacc_stable_rids['RID']=nacc_stable_rids['RID'].astype('int64')\n",
    "# comb_gmv_nacc['RID']=comb_gmv_nacc['RID'].astype('int64')\n",
    "\n",
    "rid_comb_gmv = set(comb_gmv_nacc[\"RID\"])\n",
    "rid_nacc_prog = set(nacc_prog_rids['RID'])\n",
    "rid_nacc_stab = set(nacc_stab_rids['RID'])\n",
    "\n",
    "\n",
    "nacc_gmv_prog = pd.DataFrame()\n",
    "nacc_gmv_stab = pd.DataFrame()\n",
    "\n",
    "\n",
    "#itterows allows you to iterate through rows of a df (it returns an iterator which is a pairs of index and series (the data for that row) for each row)\n",
    "for index, row in comb_gmv_nacc.iterrows():\n",
    "    rid = row[\"RID\"]\n",
    "\n",
    "    if rid in rid_nacc_prog:\n",
    "        #if that rid exists in adni_progs then append the row to adni_gmv\n",
    "        nacc_gmv_prog = nacc_gmv_prog.append(row,ignore_index=True)\n",
    "    else:  \n",
    "        nacc_gmv_stab = nacc_gmv_stab.append(row,ignore_index=True) #if they arent prog they are stab \n",
    "\n",
    "print(nacc_gmv_stab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nacc_gmv_prog \n",
    "nacc_gmv_prog = nacc_gmv_prog.drop(['RID','TIV','Dataset'], axis=1)\n",
    "nacc_gmv_stab = nacc_gmv_stab.drop(['RID','TIV','Dataset'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop regions with 0 volume \n",
    "nacc_gmv_prog = nacc_gmv_prog.drop(['vol_lInfLatVen','vol_rInfLatVen','vol_lOC','vol_rOC'], axis=1)\n",
    "nacc_gmv_stab = nacc_gmv_stab.drop(['vol_lInfLatVen','vol_rInfLatVen','vol_lOC','vol_rOC'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nacc gmv prog for 0 values\n",
    "\n",
    "# Assuming nacc_gmv_prog is your dataframe\n",
    "zero_values = (nacc_gmv_prog == 0).sum().sum()\n",
    "\n",
    "print(f'Total zero values in the DataFrame: {zero_values}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nacc_gmv_stab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I guess scale the data like from original code because it involves distance metric \n",
    "#have to do standard scalar normalization \n",
    "#it normalizes by column \n",
    "#sklearn standard scalar \n",
    "scaler = StandardScaler()\n",
    "#fit to your data and apply the transformation to your data \n",
    "nacc_progs_norm = scaler.fit_transform(nacc_gmv_prog)\n",
    "nacc_stable_norm = scaler.fit_transform(nacc_gmv_stab)\n",
    "print(nacc_progs_norm.shape)\n",
    "print(nacc_progs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the output of standard scaler is a numpy array so need to reconvert it \n",
    "nacc_progs_norm = pd.DataFrame(nacc_progs_norm, columns=nacc_gmv_prog.columns)\n",
    "nacc_stable_norm = pd.DataFrame(nacc_stable_norm,columns=nacc_gmv_stab.columns)\n",
    "print(progs_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nacc_progs_norm.isnull().sum().sum())  # Sum of NaN values\n",
    "print(nacc_progs_norm.isin([np.inf, -np.inf]).sum().sum())  # Sum of Inf values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nacc gmv prog for 0 values\n",
    "\n",
    "# Assuming nacc_gmv_prog is your dataframe\n",
    "zero_values = (nacc_progs_norm == 0).sum().sum()\n",
    "\n",
    "print(f'Total zero values in the DataFrame: {zero_values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = nacc_progs_norm.isna()\n",
    "nan_count = nan_mask.sum().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not nacc_progs_norm.isnull().values.any(), \"Initial DataFrame has NaN values\"\n",
    "assert not np.isinf(nacc_progs_norm).values.any(), \"Initial DataFrame has Inf values\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run bootstrapping (with replacement) before the graphical lasso cv () \n",
    "#random_state = None means random number generator is inistalized, produces different set of rnadom samples each time \n",
    "#setting random state to 1 so that its reproducable \n",
    "\n",
    "#set random generator outside loop \n",
    "#seed everytrhing once at begibning and dont touch it \n",
    "# np.random.seed(1)\n",
    "\n",
    "\n",
    "num_bootstrap_samples = 50\n",
    "nacc_bootstrap_precision_matrices = []\n",
    "nacc_bootstrap_samples = []\n",
    "for x in range(num_bootstrap_samples):\n",
    "    #sample with replacement, randomstate =1 for reporoducibility \n",
    "    nacc_bootstrap_sample = nacc_progs_norm.sample(n=len(nacc_progs_norm),replace=True)\n",
    "    #append resamples df to a list \n",
    "    nacc_bootstrap_samples.append(nacc_bootstrap_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nacc_bootstrap_sample.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all dataframes have the same datatypes for each column\n",
    "datatypes = nacc_bootstrap_samples[0].dtypes  # Get datatypes of the first dataframe\n",
    "same_datatypes = all((df.dtypes == datatypes).all() for df in nacc_bootstrap_samples)\n",
    "\n",
    "print(f'All dataframes have the same datatypes for each column: {same_datatypes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming nacc_bootstrap_samples is your list of DataFrames\n",
    "for i, df in enumerate(nacc_bootstrap_samples):\n",
    "    if df.isnull().values.any():\n",
    "        print(f'NaN values found in DataFrame at index {i}')\n",
    "    else:\n",
    "        print(f'No NaN values found in DataFrame at index {i}')\n",
    "\n",
    "# If you want to see the total count of NaN values across all DataFrames:\n",
    "total_nan_count = sum(df.isnull().sum().sum() for df in nacc_bootstrap_samples)\n",
    "print(f'Total NaN count across all DataFrames: {total_nan_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming nacc_bootstrap_samples is your list of DataFrames\n",
    "for i, df in enumerate(nacc_bootstrap_samples):\n",
    "    if np.isinf(df).values.any():\n",
    "        print(f'Infinite values found in DataFrame at index {i}')\n",
    "    else:\n",
    "        print(f'No infinite values found in DataFrame at index {i}')\n",
    "\n",
    "# If you want to see the total count of infinite values across all DataFrames:\n",
    "total_inf_count = sum(np.isinf(df).sum().sum() for df in nacc_bootstrap_samples)\n",
    "print(f'Total infinite count across all DataFrames: {total_inf_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, value in enumerate(nacc_bootstrap_samples):\n",
    "#     if math.isnan(value):\n",
    "#         print(f'NaN found at index {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run graphical model on bootstrapped sample \n",
    "#it worked changing the random seed so fingers crossed \n",
    "#setting random seed to 3 changed it so it wasn't generating sample with inf or nan values \n",
    "#setting random seed as 3 and 100 samples works \n",
    "nacc_models = []\n",
    "for nacc_bootstrap_sample in tqdm(nacc_bootstrap_samples):\n",
    "    nacc_model = GraphicalLassoCV(cv=5,max_iter=50, tol=1e-3)\n",
    "    nacc_model.fit(nacc_bootstrap_sample)\n",
    "    nacc_models.append(nacc_model) \n",
    "\n",
    "#error that it must not contain infs or nans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check for nan or inf values - dont need anymore since I fixed it \n",
    "\n",
    "# #I don't need to use this because the 100 samples + random seed 3 is good without it \n",
    "# nacc_models = []\n",
    "# for nacc_bootstrap_sample in tqdm(nacc_bootstrap_samples):\n",
    "#     if nacc_bootstrap_sample.isnull().values.any() or np.isinf(nacc_bootstrap_sample).values.any():\n",
    "#         print('NaN or Inf found')\n",
    "#     nacc_model = GraphicalLassoCV(cv=2,max_iter=50, tol=1e-3)\n",
    "#     nacc_model.fit(nacc_bootstrap_sample)\n",
    "#     nacc_models.append(nacc_model)\n",
    "\n",
    "# #try logging \n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# nacc_models = []\n",
    "# for idx, nacc_bootstrap_sample in enumerate(tqdm(nacc_bootstrap_samples)):\n",
    "#     # Check for NaN/Inf values\n",
    "#     if nacc_bootstrap_sample.isnull().values.any() or np.isinf(nacc_bootstrap_sample).values.any():\n",
    "#         logging.info(f'NaN or Inf found in sample {idx}')\n",
    "\n",
    "#     # Try to fit the model\n",
    "#     #try and except block structure \n",
    "#     try:\n",
    "#         nacc_model = GraphicalLassoCV(cv=2, max_iter=50, tol=1e-3)\n",
    "#         nacc_model.fit(nacc_bootstrap_sample)\n",
    "#         nacc_models.append(nacc_model)\n",
    "#     except ValueError as e:\n",
    "#         logging.error(f'Error encountered in sample {idx}: {e}')\n",
    "#         logging.error(f'Data: {nacc_bootstrap_sample}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need anymore I fixed the issue \n",
    "# import logging\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# from sklearn.covariance import GraphicalLassoCV\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# nacc_models = []\n",
    "# for idx, nacc_bootstrap_sample in enumerate(tqdm(nacc_bootstrap_samples)):\n",
    "#     # Locate NaN and Inf values\n",
    "#     nan_locations = nacc_bootstrap_sample.isnull().stack()[lambda x: x]\n",
    "#     inf_locations = nacc_bootstrap_sample.isin([np.inf, -np.inf]).stack()[lambda x: x]\n",
    "\n",
    "#     if not nan_locations.empty or not inf_locations.empty:\n",
    "#         logging.info(f'NaN or Inf found in sample {idx}')\n",
    "#         for location in nan_locations.index:\n",
    "#             logging.info(f'NaN found at row {location[0]}, column {location[1]}')\n",
    "#         for location in inf_locations.index:\n",
    "#             logging.info(f'Inf found at row {location[0]}, column {location[1]}')\n",
    "\n",
    "#     # Try to fit the model\n",
    "#     try:\n",
    "#         nacc_model = GraphicalLassoCV(cv=2, max_iter=50, tol=1e-3)\n",
    "#         nacc_model.fit(nacc_bootstrap_sample)\n",
    "#         nacc_models.append(nacc_model)\n",
    "#     except ValueError as e:\n",
    "#         logging.error(f'Error encountered in sample {idx}: {e}')\n",
    "#         logging.error(f'Data: {nacc_bootstrap_sample}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so there is one model that is throwing off the whole code in this \n",
    "print(len(nacc_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc metrics - I think it was calcing the adni prog one (but they still look the same)\n",
    "# iterating through each bootsrap sample model, calculating the graph metrics, and then storing the metrics for eahc model in a dataframe \n",
    "nacc_metrics_data = []\n",
    "\n",
    "#keep track of index with enumerate \n",
    "for nacc_model_num, nacc_model in enumerate(nacc_models,start=1):\n",
    "    nacc_precision_matrix_p = nacc_model.precision_\n",
    "    np.fill_diagonal(nacc_precision_matrix_p, 0) #removes self connections by replacing the diagnonal of matrix with 0 \n",
    "    nacc_G_prog = nx.Graph(nacc_precision_matrix_p)\n",
    "    nacc_node_labels = {i: label for i, label in enumerate(nacc_progs_norm.columns)}\n",
    "    #relabel the nodes in the graph using the dictionary\n",
    "    nacc_G_prog = nx.relabel_nodes(nacc_G_prog, nacc_node_labels)\n",
    "    #now calculate the metrics and store them \n",
    "    nacc_gpe = nx.global_efficiency(nacc_G_prog) \n",
    "    nacc_clustering_coefficient = nx.average_clustering(nacc_G_prog)\n",
    "    nacc_density = nx.density(nacc_G_prog)\n",
    "    # eigen_cen = nx.eigenvector_centrality(G_prog)\n",
    "    nacc_ass_coeff = nx.degree_assortativity_coefficient(nacc_G_prog)\n",
    "    # diameter = nx.diameter(G_prog)\n",
    "    # radius = nx.radius(G_prog)\n",
    "\n",
    "\n",
    "    #create dictionary for current models data \n",
    "    nacc_metrics_dic = {\n",
    "        'model_num': nacc_model_num,\n",
    "        'gpe': nacc_gpe,\n",
    "        'clus_coeff':nacc_clustering_coefficient,\n",
    "        'density': nacc_density,\n",
    "        'ass_coeff': nacc_ass_coeff\n",
    "    }\n",
    "    nacc_metrics_data.append(nacc_metrics_dic)\n",
    "\n",
    "\n",
    "#turn the list of dictionaries with each model info into a df\n",
    "nacc_metrics_data = pd.DataFrame(nacc_metrics_data)\n",
    "nacc_metrics_data.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/full_bootstrap_models_prog_metrics_nacc.csv')\n",
    "# print(metrics_data.dtypes)\n",
    "print(nacc_metrics_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nacc_gmv_stab\n",
    "#run bootstrap for stable df \n",
    "# np.random.seed(3)\n",
    "nacc_stab_num_bootstrap_samples = 50\n",
    "nacc_stab_bootstrap_precision_matrices = []\n",
    "nacc_stab_bootstrap_samples = []\n",
    "for x in range(nacc_stab_num_bootstrap_samples):\n",
    "    #sample with replacement, randomstate =1 for reporoducibility \n",
    "    nacc_stab_bootstrap_sample = stable_norm.sample(n=len(stable_norm),replace=True)\n",
    "    #append resamples df to a list \n",
    "    nacc_stab_bootstrap_samples.append(nacc_stab_bootstrap_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run graphical model on bootstrapped sample \n",
    "nacc_stab_models = []\n",
    "for nacc_stab_bootstrap_sample in tqdm(nacc_stab_bootstrap_samples):\n",
    "    #if I give it alphas [1,10] it looks like it drops almost all of the connections \n",
    "    \n",
    "    nacc_stab_model = GraphicalLassoCV(cv=5,max_iter=50,tol=1e-3)\n",
    "    nacc_stab_model.fit(nacc_stab_bootstrap_sample)\n",
    "    nacc_stab_models.append(nacc_stab_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nacc_stab_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming stable_norm and stab_models are already defined somewhere\n",
    "\n",
    "nacc_stab_metrics_data = []\n",
    "\n",
    "for nacc_model_num, nacc_stab_model in enumerate(nacc_stab_models):\n",
    "    nacc_precision_matrix_stab = nacc_stab_model.precision_\n",
    "    np.fill_diagonal(nacc_precision_matrix_stab, 0)  # removes self connections by replacing the diagonal of matrix with 0\n",
    "    nacc_G_stab = nx.Graph(nacc_precision_matrix_stab)\n",
    "    # create a dictionary that maps old node labels to new node labels\n",
    "    naccstab_node_labels = {i: label for i, label in enumerate(nacc_stable_norm.columns)}\n",
    "    # relabel the nodes in the graph using the dictionary\n",
    "    nacc_G_stab = nx.relabel_nodes(nacc_G_stab, naccstab_node_labels)\n",
    "    # now calculate the metrics and store them\n",
    "    nacc_stab_gpe = nx.global_efficiency(nacc_G_stab)\n",
    "    nacc_stab_clustering_coefficient = nx.average_clustering(nacc_G_stab)\n",
    "\n",
    "    # Assuming you want to store metrics for stab (stability) models,\n",
    "    # not prog (progression) models as shown in the second snippet\n",
    "    nacc_stab_density = nx.density(nacc_G_stab)\n",
    "    nacc_stab_ass_coeff = nx.degree_assortativity_coefficient(nacc_G_stab)\n",
    "\n",
    "    # metrics dictionary\n",
    "    nacc_stab_metrics_dic = {'model_num': nacc_model_num,\n",
    "                        'gpe': nacc_stab_gpe,\n",
    "                        'clus_coeff': nacc_stab_clustering_coefficient,\n",
    "                        'density': nacc_stab_density,\n",
    "                        'ass_coeff': nacc_stab_ass_coeff\n",
    "                        }\n",
    "\n",
    "    nacc_stab_metrics_data.append(nacc_stab_metrics_dic)\n",
    "\n",
    "nacc_stab_metrics_data = pd.DataFrame(nacc_stab_metrics_data)\n",
    "nacc_stab_metrics_data.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/50_bootstrap_models_stab_metrics_nacc.csv')\n",
    "print(nacc_stab_metrics_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(nacc_metrics_data.shape)\n",
    "print(nacc_stab_metrics_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nacc t test \n",
    "#instead of calcing mean just calc from data instead \n",
    "#add col where the p val is greater than .05\n",
    "\n",
    "# Initialize lists or a DataFrame to store your results\n",
    "cols = []\n",
    "p_values = []\n",
    "t_stats = []\n",
    "\n",
    "# Note: The dataframe should be adni_gmv_progs, not adni_gmv_prog\n",
    "for col in nacc_metrics_data.columns:  \n",
    "    if col != 'model_num':\n",
    "    # Get data for this brain region from both datasets\n",
    "        nacc_progs_data = nacc_metrics_data[col]\n",
    "        nacc_stab_data = nacc_stab_metrics_data[col]\n",
    "        \n",
    "        # Perform t-test\n",
    "        t_stat, p_val = stats.ttest_ind(nacc_progs_data, nacc_stab_data, equal_var=False)  # Assuming variance might not be equal\n",
    "        \n",
    "        # Store results\n",
    "        cols.append(col)\n",
    "        t_stats.append(t_stat)\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # Combine results into a DataFrame for easy viewing and further analysis\n",
    "    nacc_results_df = pd.DataFrame({\n",
    "        'Brain Region': cols,\n",
    "        'T-Statistic': t_stats,\n",
    "        'P-Value': p_values\n",
    "})\n",
    "\n",
    "# Adding the Significant column based on the P-Value\n",
    "nacc_results_df['Significant'] = nacc_results_df['P-Value'] < 0.05\n",
    "\n",
    "# Display or save the results\n",
    "print(\"Nacc t test results between nacc prog and nacc stab\")\n",
    "print(nacc_results_df)\n",
    "# Optionally save to a CSV file\n",
    "# results_df.to_csv('t_test_results.csv', index=False)\n",
    "\n",
    "#The results previously have been saved so I could even just load them \n",
    "#the resulting negative t stats mean the progs have lower volume than the stab which is good \n",
    "nacc_results_df.to_csv('/data2/MRI_PET_DATA/graph/csvs/bootstrap_models_and_metrics/50_bootstrap_models_ttest_nacc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adni t test results between adni prog and adni stab\")\n",
    "print(results_df)\n",
    "#andi and nacc results are the exact same so need to figure out why they are not "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
